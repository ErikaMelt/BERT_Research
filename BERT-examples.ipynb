{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4cfe1d",
   "metadata": {},
   "source": [
    "### Ejemplo: Fill - Mask  \n",
    "\n",
    "\n",
    "You can use the ü§ó Transformers library fill-mask pipeline to do inference with masked language models. If a model name is not provided, the pipeline will be initialized with distilroberta-base. You can provide masked text and it will return a list of possible mask values ‚Äã‚Äãranked according to the score.\n",
    "\n",
    "\n",
    "Fuente: /cite{FillMask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a59713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/anaconda3/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731a305",
   "metadata": {},
   "source": [
    "**Paso 2**\n",
    "\n",
    "Ejecutar este comando para importar el pipeline que es una libreria de Transformers  fill-mask,  el pipeline recibe como par√°metro el modelo en este caso vamos a usar bert-base-uncased, por defecto el modelo usado es distilroberta-base.  \n",
    "\n",
    "El resultado esperado es una lista con posibles valores para la palabra oculta (MASK) ordenados de acuerdo con el score obtenido.  \n",
    "\n",
    "El uso de estos modelos no require datos etiquetados, y se entrenan pasando frases con palabras ocultas, el resultado esperado es que el modelo adivine la palabra oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d0773d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49b99d",
   "metadata": {},
   "source": [
    "**Paso 3** \n",
    "\n",
    "Llamar la funci√≥n unmasker y pasar la frase con la palabra MASKED que queremos predecir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bb388e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3182411193847656,\n",
       "  'token': 2064,\n",
       "  'token_str': 'can',\n",
       "  'sequence': 'artificial intelligence can take over the world.'},\n",
       " {'score': 0.1829962283372879,\n",
       "  'token': 2097,\n",
       "  'token_str': 'will',\n",
       "  'sequence': 'artificial intelligence will take over the world.'},\n",
       " {'score': 0.05600151792168617,\n",
       "  'token': 2000,\n",
       "  'token_str': 'to',\n",
       "  'sequence': 'artificial intelligence to take over the world.'},\n",
       " {'score': 0.04519502446055412,\n",
       "  'token': 2015,\n",
       "  'token_str': '##s',\n",
       "  'sequence': 'artificial intelligences take over the world.'},\n",
       " {'score': 0.04515310749411583,\n",
       "  'token': 2052,\n",
       "  'token_str': 'would',\n",
       "  'sequence': 'artificial intelligence would take over the world.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Artificial Intelligence [MASK] take over the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f7e34",
   "metadata": {},
   "source": [
    "**Paso 4**\n",
    "\n",
    "Llamar la funci√≥n unmasker para la misma frase pero en Espa√±ol y observar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576ae996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2017439901828766,\n",
       "  'token': 2050,\n",
       "  'token_str': '##a',\n",
       "  'sequence': 'inteligencia artificiala conquistar el mundo.'},\n",
       " {'score': 0.16341248154640198,\n",
       "  'token': 27893,\n",
       "  'token_str': '##idad',\n",
       "  'sequence': 'inteligencia artificialidad conquistar el mundo.'},\n",
       " {'score': 0.12584763765335083,\n",
       "  'token': 1061,\n",
       "  'token_str': 'y',\n",
       "  'sequence': 'inteligencia artificial y conquistar el mundo.'},\n",
       " {'score': 0.10195942968130112,\n",
       "  'token': 2721,\n",
       "  'token_str': '##la',\n",
       "  'sequence': 'inteligencia artificialla conquistar el mundo.'},\n",
       " {'score': 0.054612696170806885,\n",
       "  'token': 2401,\n",
       "  'token_str': '##ia',\n",
       "  'sequence': 'inteligencia artificialia conquistar el mundo.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Inteligencia Artificial [MASK] conquistar el mundo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3336f0",
   "metadata": {},
   "source": [
    "### Ejemplo: An√°lisis de Sentimiento\n",
    "\n",
    "En este ejemplo vamos a usar dos frases en Espa√±ol que expresan sentimiento positivo y negativo, con el objetivo de verificar que el algoritmo nos detecta el sentimiento correcto para cada frase. \n",
    "\n",
    "Fuente: /cite{perez2021pysentimiento}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecd7a3",
   "metadata": {},
   "source": [
    "**Paso 1**\n",
    "\n",
    "Correr el comando para instalar la libreria pysentimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f70984",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b2b53",
   "metadata": {},
   "source": [
    "**Paso 2**\n",
    "\n",
    "Importar la funci√≥n create_analyzer, que nos permitir√° pasar como par√°metro una tarea como: \n",
    "- sentiment = Permite predecir el sentimiento ya sea positivo o negativo de una frase. \n",
    "- emotion = Permite predecir la emoci√≥n que se expresa en una frase, por ejemplo rabia, alegria, tristeza, felicidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7acc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e1402",
   "metadata": {},
   "source": [
    "**Paso 3**\n",
    "\n",
    "Llamar la funcion create_analyzer pasando como par√°metro task=\"sentiment\" y lang=\"es\",  esto nos crea un objeto analyzer el cual tiene la funci√≥n predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e40d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0f43e",
   "metadata": {},
   "source": [
    "**Paso 4**\n",
    "\n",
    "Pasar como par√°metro la frase:  Hoy es un d√≠a maravilloso, el output esperado es POS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b423b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.998, NEU: 0.001, NEG: 0.001})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Hoy es un dia maravilloso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73bb284",
   "metadata": {},
   "source": [
    "**Paso 5**\n",
    "\n",
    "Pasar como par√°metro la frase:  Hoy es un d√≠a gris y muy fr√≠o, el output esperado es NEG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35e4dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.997, NEU: 0.003, POS: 0.000})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Hoy es un dia gris y muy frio.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71e0bd",
   "metadata": {},
   "source": [
    "### Ejemplo: An√°lisis de Emociones\n",
    "\n",
    "En este ejemplo vamos a utilizar el an√°lisis de emociones para predecir la emoci√≥n que se expresa en dos frases en Ingl√©s, una frase expresa Alegria y la otra frase expresa tristeza. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b148b",
   "metadata": {},
   "source": [
    "**Paso 1** \n",
    "\n",
    "Llamar la funcion create_analyzer pasando como par√°metro la task=\"emotion\" y lang=\"en\", esto nos inicializar√° un objeto emotion_analyzer,  el cu√°l expone el m√©todo predict.  A este m√©todo le pasamos como par√°metro la frase que queremos predecir y el nos devuelve como output el nombre de la emoci√≥n que predijo de acuerdo con la frase enviada como input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e994288",
   "metadata": {},
   "source": [
    "**Paso 2**\n",
    "\n",
    "Llamar la funcion predict y pasar como par√°metro la frase \"I'm over the moon\" que expresa emoci√≥n alegria y observar el output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7b89d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=joy, probas={joy: 0.972, others: 0.019, surprise: 0.003, sadness: 0.002, anger: 0.001, fear: 0.001, disgust: 0.001})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_analyzer.predict(\"I'm over the moon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6302996",
   "metadata": {},
   "source": [
    "**Paso 3**\n",
    "\n",
    "Llamar la funcion predict y pasar como par√°metro la frase \"She is feeling blue\" que expresa emoci√≥n de tristeza y observar el output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1db851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=others, probas={others: 0.936, joy: 0.034, sadness: 0.015, fear: 0.006, surprise: 0.004, disgust: 0.003, anger: 0.002})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_analyzer.predict(\"She is feeling blue\")"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Erika Paola Ortiz"
   },
   {
    "name": "Romina Iglesias"
   }
  ],
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "title": "Hablemos de BERT Red Neuronal",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "95px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.852px",
    "left": "1311px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
