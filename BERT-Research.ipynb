{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39ac1d4",
   "metadata": {},
   "source": [
    "---\n",
    "title: Hablemos de BERT\n",
    "author: Erika Paola Ortiz y Romina Soledad Iglesias \n",
    "date: today\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48be32",
   "metadata": {},
   "source": [
    "# Resumen\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5eecc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c47a4a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5427963c",
   "metadata": {},
   "source": [
    "# Palabras clave\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf720c",
   "metadata": {},
   "source": [
    "- **BERT**: Bidirectional Encoder Representations from Transformers\n",
    "\n",
    "- **PLN:** Procesamiento de Lenguaje Natural  (NLP en Inglés): Es un campo de las ciencias de la computación, de la inteligencia artificial y de la lingüística que estudia las interacciones entre las computadoras y el lenguaje humano. Se ocupa de la formulación e investigación de mecanismos eficaces computacionalmente para la comunicación entre personas y máquinas por medio del lenguaje natural, es decir, de las lenguas del mundo.\n",
    "\n",
    "- **Deep Learning:** Aprendizaje profundo (en inglés, deep learning) es un conjunto de algoritmos de aprendizaje automático (en inglés, machine learning) que intenta modelar abstracciones de alto nivel en datos usando arquitecturas computacionales que admiten transformaciones no lineales múltiples e iterativas de datos expresados en forma matricial o tensorial. \n",
    "\n",
    "* **Machine learning:** es una disciplina, dentro de la Inteligencia Artificial, donde se estudian métodos para hacer predicciones, que podamos programar y automatizar. Machine Learning dota a las máquinas de la capacidad de aprender.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acfcbc",
   "metadata": {},
   "source": [
    "# Introducción\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925d601",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3ec91",
   "metadata": {},
   "source": [
    "# Objetivos y Metodología\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485390a2",
   "metadata": {},
   "source": [
    "- Explicar el concepto de BERT. \n",
    "- Identificar las aplicaciones del modelo BERT. \n",
    "- Presentar un demo de algunas de las aplicaciones de BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e1284",
   "metadata": {},
   "source": [
    "# Resultados y Discusión\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b467c22",
   "metadata": {},
   "source": [
    "## ¿Qué es BERT?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49fa9c",
   "metadata": {},
   "source": [
    "\n",
    "BERT Bidirectional Encoder Representations from Transformers por sus siglas en Inglés en español significa Representación de Codificador Bidireccional de Transformadores. \n",
    " \n",
    "BERT es un modelo de machine learning que se utiliza como una técnica para el procesamiento de lenguaje natural. BERT está basada en el uso de redes neuronales Transformers. \n",
    " \n",
    " \n",
    "**Redes Neuronales Transformers**\n",
    "\n",
    "Las redes neuronales Transformers son modelos que tienen diversas aplicaciones como traducir textos, escribir poemas, sintetizar y/o generar texto, generar código fuente entre otras aplicaciones. \n",
    " \n",
    "Las redes transformers fueron creados por Google en  2017 y por la Universidad de Toronto y su enfoque principal era realizar traducciones, pero puede ser entrenado para diferentes usos ya que gracias a la alta capacidad de procesamiento en paralelo los transformadores son más eficientes reduciendo el tiempo y facilidad de entrenamiento y aumentando el tamaño de los set de datos que pueden procesar. \n",
    " \n",
    "Los transformers están basados en tres principales innovaciones: \n",
    "- Positioning encoding\n",
    "- Attention\n",
    "- Self attention. \n",
    "\n",
    "A continuación explicamos en qué consiste cada una de las tres principales innovaciones:\n",
    "En realidad no sé si pondría esto, lo explicaría de forma general, sin tener que entrar en detalle en cada uno, porque se me hace muy dificil hacer una explicación sin copiar del texto.\n",
    " \n",
    "- **Positioning Encoding**\n",
    "\n",
    "Los transformers utilizan codificadores posicionales para etiquetar elementos de datos que entran y salen de la red. \n",
    "\n",
    "El Transformer recibe una oración de entrada y la convierte en dos secuencias: una secuencia de vectores de palabras y una secuencia de codificaciones posicionales. Ambos vectores son escritos usando representaciones numéricas del texto para que la red neuronal pueda procesarlas. Cada palabra del diccionario se representa como un vector. Las codificaciones posicionales son una representación vectorial de la posición de la palabra en la oración original.\n",
    "El transformer junta ambas secuencias y pasa el resultado a través de una serie de codificadores, seguidos de una serie de decodificadores. Esto es necesario debido a que el input no es alimentado en la red de forma secuencial sino que se pasa todo de una vez.\n",
    "\n",
    " \n",
    "- **Attention**\n",
    "Attention es un mecanismo que permite a un modelo de texto «mirar» cada una de las palabras de la frase original al tomar una decisión sobre cómo traducir las palabras de la frase de salida.\n",
    " \n",
    "Este modelo aprende de los datos de entrenamiento. Por ejemplo, en el caso de los traductores, al ver miles de ejemplos de frases en diferentes idiomas, el modelo aprende qué tipos de palabras son interdependientes. De esta manera aprende a respetar el género, la pluralidad y otras reglas gramaticales.\n",
    " \n",
    " \n",
    "- **Self attention**\n",
    " \n",
    "El mecanismo Self attention es lo que permite al modelo saber con qué otra palabra de la oración está relacionada la palabra que se procesa en ese instante de tiempo. \n",
    " \n",
    "una capa que ayuda al codificador a ver otras palabras en la oración de entrada mientras codifica una palabra específica.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17405d6",
   "metadata": {},
   "source": [
    "## Aplicaciones de BERT \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42c3e5",
   "metadata": {},
   "source": [
    "Las aplicaciones de modelos como BERT tienen aplicación en problemas de la vida cotidiana como: \n",
    "Traducción de textos. \n",
    "Generación de documentos. \n",
    "Resumen de textos. \n",
    "Análisis de secuencias biológicas. \n",
    "Analisis de videos.\n",
    "NER Named Entity Recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4f1f6",
   "metadata": {},
   "source": [
    "# Conclusiones\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f32bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ed07ed1",
   "metadata": {},
   "source": [
    "# Referencias bibliográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cc38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "95px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.852px",
    "left": "1311px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
