@article{perez2021pysentimiento,
      title={pysentimiento: A Python Toolkit for Sentiment Analysis and SocialNLP tasks},
      author={Juan Manuel Pérez and Juan Carlos Giudici and Franco Luque},
      year={2021},
      eprint={2106.09462},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
},
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}, 
@online{BERTSearch,
  author = {Pandu Nayak. Google Fellow and Vice President, Search},
  title = {{Understanding searches better than ever before}},
  year = 2019,
  url = {https://www.blog.google/products/search/search-language-understanding-bert/},
  urldate = {2019-10-25}
}, 
@online{BERTDifferences,
  author = {Lavanya Gupta. Medium Blog},
  title = {{Differences Between Word2Vec and BERT}},
  year = 2020,
  url = {https://medium.com/swlh/differences-between-word2vec-and-bert-c08a3326b5d1#:~:text=Word2Vec%20will%20g},
  urldate = {2020-11-12}
}, 
@online{Transformers,
  title = {{Transformers: Redes Neuronales}},
  year = 2021,
  url = {https://www.linkedin.com/pulse/transformers-redes-neuronales-cristian-santander/?originalSubdomain=es},
  urldate = {2021-04-14}
}, 
@online{Transformers1,
  title = {{Differences Between Word2Vec and BERT}},
  year = 2012,
  url = {https://daleonai.com/transformers-explained},
  urldate = {2021-05-06}
}, 
@mastersthesis{BERTModel,
  author  = "Iago Collarte González",
  title   = "Procesamiento del lenguaje natural
con BERT: Análisis de sentimientos en tuits",
  school  = "Universidad Carlos 3 de Madrid",
  year    = "2020"
}



