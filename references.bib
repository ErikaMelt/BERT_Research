@article{perez2021pysentimiento,
      title={pysentimiento: A Python Toolkit for Sentiment Analysis and SocialNLP tasks},
      author={Juan Manuel Pérez and Juan Carlos Giudici and Franco Luque},
      year={2021},
      eprint={2106.09462},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
},
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}, 
@online{BERTSearch,
  author = {Pandu Nayak. Google Fellow and Vice President, Search},
  title = {{Understanding searches better than ever before}},
  year = 2019,
  url = {https://www.blog.google/products/search/search-language-understanding-bert/},
  urldate = {2019-10-25}
}, 
@online{BERTDifferences,
  author = {Lavanya Gupta. Medium Blog},
  title = {{Differences Between Word2Vec and BERT}},
  year = 2020,
  url = {https://medium.com/swlh/differences-between-word2vec-and-bert-c08a3326b5d1#:~:text=Word2Vec%20will%20g},
  urldate = {2020-11-12}
}, 
@online{Transformers,
  title = {{Transformers: Redes Neuronales}},
  year = 2021,
  url = {https://www.linkedin.com/pulse/transformers-redes-neuronales-cristian-santander/?originalSubdomain=es},
  urldate = {2021-04-14}
}, 
@online{Transformers1,
  title = {{Differences Between Word2Vec and BERT}},
  year = 2012,
  url = {https://daleonai.com/transformers-explained},
  urldate = {2021-05-06}
}, 
@mastersthesis{BERTModel,
  author  = "Iago Collarte González",
  title   = "Procesamiento del lenguaje natural
con BERT: Análisis de sentimientos en tuits",
  school  = "Universidad Carlos 3 de Madrid",
  year    = "2020" 
}, 
@online{FillMask,
  title = {{Fill-Mask - Huggingface}},
  year = 2022,
  url = {https://huggingface.co/tasks/fill-mask}
},
@online{BERTExplained,
  title = {{BERT Explained a complete guide}},
  year = 2017,
  url = {https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c}
},
@online{DocBERT,
  title = {{DocBERT for Document Classification}},
  url = {https://www.researchgate.net/publication/332493790_DocBERT_BERT_for_Document_Classification}
},
@online{bioBERT,
  title = {{bioBERT Explained}},
  url = {https://arxiv.org/ftp/arxiv/papers/1901/1901.08746.pdf}
},
@online{VideoBERT,
  title = {{VideoBERT a joint model for video and Language Representation Learning}},
  url = {https://www.researchgate.net/publication/332186832_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning}
},
@online{SciBERT,
  title = {{SciBERT Explained}},
  url = {https://aclanthology.org/D19-1371.pdf}
},
@article{shang2019pre,
  title={Pre-training of graph augmented transformers for medication recommendation},
  author={Shang, Junyuan and Ma, Tengfei and Xiao, Cao and Sun, Jimeng},
  journal={arXiv preprint arXiv:1906.00346},
  year={2019}
},
@online{patentBERT,
  title = {{patentBERT Explained}},
  url = {https://www.kaggle.com/datasets/danofer/patentbert}
},
@online{RoBERTa,
  title = {{Roberta Explained}},
  url = {https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/}
},
@online{XLM-R,
  title = {{XLM-R Explained}},
  url = {https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/}
},
@online{DistilBERT,
  title = {{DistilBERT}},
  url = {https://huggingface.co/docs/transformers/model_doc/distilbert}
}, 
@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}, 
@online{GloVe,
  title = {{GloVe Aprendizaje Automático}},
  url = {https://hmong.es/wiki/GloVe_(machine_learning)}
}, 
@online{ElmoBert,
  author = {Ryan Burke},
  title = {{GloVe, ELMo y BERT. A guide to state-of-the-art text classification using Spark NLP}},
  url = {https://towardsdatascience.com/glove-elmo-bert-9dbbc9226934},
  urldate = {2021-03-16}
}